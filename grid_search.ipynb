{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using skorch with embeddings net for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "import glob\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch import NeuralNetClassifier\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data\n",
    "def save_spectrogram_tisv(audio_path, tisv_frame=180, hop=0.01, window=0.0025, sr=8000, nfft=512, nmels=40):\n",
    "    \"\"\" Full preprocess of text independent utterance. The log-mel-spectrogram is saved as numpy file.\n",
    "        Each partial utterance is splitted by voice detection using DB\n",
    "        and the first and the last 180 frames from each partial utterance are saved. \n",
    "        Need : utterance data set\n",
    "    \"\"\"\n",
    "    print(\"start text independent utterance feature extraction\")\n",
    "    audio_path = glob.glob(os.path.dirname(audio_path))\n",
    "    rmtree('./train_tisv/', ignore_errors=True)\n",
    "    rmtree('./test_tisv/', ignore_errors=True)\n",
    "    os.makedirs('./train_tisv', exist_ok=True)   # make folder to save train file\n",
    "    os.makedirs('./test_tisv', exist_ok=True)    # make folder to save test file\n",
    "    _no_sound_found = 0\n",
    "    _minium_name_file_per_speaker = 10000\n",
    "    utter_min_len = (tisv_frame * hop + window) * sr    # lower bound of utterance length\n",
    "    total_speaker_num = len(audio_path)\n",
    "    train_speaker_num= (total_speaker_num//10)*9            # split total data 90% train and 10% test\n",
    "    print(\"total speaker number : %d\"%total_speaker_num)\n",
    "    print(\"train : %d, test : %d\"%(train_speaker_num, total_speaker_num-train_speaker_num))\n",
    "    for i, folder in enumerate(audio_path):\n",
    "        print(\"%dth speaker processing...\"%i)\n",
    "        utterances_spec = []\n",
    "        for utter_name in os.listdir(folder):\n",
    "            if utter_name[-4:] == '.wav':\n",
    "                utter_path = os.path.join(folder, utter_name)         # path of each utterance\n",
    "                utter, sr = librosa.core.load(utter_path, sr)        # load utterance audio\n",
    "                intervals = librosa.effects.split(utter, top_db=30)         # voice activity detection\n",
    "                for interval in intervals:\n",
    "                    if (interval[1]-interval[0]) > utter_min_len:           # If partial utterance is sufficient long,\n",
    "                        utter_part = utter[interval[0]:interval[1]]         # save first and last 180 frames of spectrogram.\n",
    "                        S = librosa.core.stft(y=utter_part, n_fft=nfft,\n",
    "                                              win_length=int(window * sr), hop_length=int(hop * sr))\n",
    "                        S = np.abs(S) ** 2\n",
    "                        mel_basis = librosa.filters.mel(sr=sr, n_fft=nfft, n_mels=nmels)\n",
    "                        S = np.log10(np.dot(mel_basis, S) + 1e-6)           # log mel spectrogram of utterances\n",
    "                        utterances_spec.append(S[:, :tisv_frame])    # first 180 frames of partial utterance\n",
    "                        utterances_spec.append(S[:, -tisv_frame:])   # last 180 frames of partial utterance\n",
    "\n",
    "        utterances_spec = np.array(utterances_spec)\n",
    "        if utterances_spec.shape[0] < 6:\n",
    "            print(f\"{i}th speaker {folder} not enough files\")\n",
    "            continue\n",
    "        if utterances_spec.shape[0] < _minium_name_file_per_speaker:\n",
    "            _minium_name_file_per_speaker = utterances_spec.shape[0]\n",
    "        if i < train_speaker_num:\n",
    "            np.save(os.path.join('./train_tisv', \"speaker%d.npy\" % i), utterances_spec)        \n",
    "        else:\n",
    "            np.save(os.path.join('./test_tisv', f\"speaker{i-train_speaker_num}\"), utterances_spec)\n",
    "        print(utterances_spec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "audio_path = '/storage/company_old/*/*.wav'\n",
    "save_spectrogram_tisv(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BUG\n",
    "1. TypeError: 无法把网络放到gridsearch里面.\n",
    "2. missing one parameter: embeddings in forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get cossim\n",
    "def get_cossim(embeddings, centroids):\n",
    "    # number of utterances per speaker\n",
    "    num_utterances = embeddings.shape[1]\n",
    "    utterance_centroids = get_utterance_centroids(embeddings)\n",
    "\n",
    "    # flatten the embeddings and utterance centroids to just utterance,\n",
    "    # so we can do cosine similarity\n",
    "    utterance_centroids_flat = utterance_centroids.flatten(0, 1)\n",
    "    embeddings_flat = embeddings.flatten(0, 1)\n",
    "    # the cosine distance between utterance and the associated centroids\n",
    "    # for that utterance\n",
    "    # this is each speaker's utterances against his own centroid, but each\n",
    "    # comparison centroid has the current utterance removed\n",
    "    cos_same = F.cosine_similarity(embeddings_flat, utterance_centroids_flat)\n",
    "    # now we get the cosine distance between each utterance and the other speakers'\n",
    "    # centroids\n",
    "    # to do so requires comparing each utterance to each centroid. To keep the\n",
    "    # operation fast, we vectorize by using matrices L (embeddings) and\n",
    "    # R (centroids) where L has each utterance repeated sequentially for all\n",
    "    # comparisons and R has the entire centroids frame repeated for each utterance\n",
    "    centroids_expand = centroids.repeat((num_utterances * embeddings.shape[0], 1))\n",
    "    embeddings_expand = embeddings_flat.unsqueeze(1).repeat(1, embeddings.shape[0], 1)\n",
    "    embeddings_expand = embeddings_expand.flatten(0, 1)\n",
    "    cos_diff = F.cosine_similarity(embeddings_expand, centroids_expand)\n",
    "    cos_diff = cos_diff.view(embeddings.size(0),num_utterances,centroids.size(0))\n",
    "    # assign the cosine distance for same speakers to the proper idx\n",
    "    same_idx = list(range(embeddings.size(0)))\n",
    "    cos_diff[same_idx, :, same_idx] = cos_same.view(embeddings.shape[0], num_utterances)\n",
    "    cos_diff = cos_diff + 1e-6\n",
    "    return cos_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(embeddings):\n",
    "    centroids = embeddings.mean(dim=1)\n",
    "    return centroids\n",
    "\n",
    "def get_utterance_centroids(embeddings):\n",
    "    \"\"\"\n",
    "    Returns the centroids for each utterance of a speaker, where\n",
    "    the utterance centroid is the speaker centroid without considering\n",
    "    this utterance\n",
    "\n",
    "    Shape of embeddings should be:\n",
    "    (speaker_ct, utterance_per_speaker_ct, embedding_size)\n",
    "    这里(N, M, proj)->(N, k, proj)\n",
    "    意思是对于每一个人(N), 求除了本身之外的utt的均值.\n",
    "    例如, ouput.shape == (4, 3, 64), 那么一个对于output[0][0], 就是除了本身之外的另外两个的均值.\n",
    "    \"\"\"\n",
    "    sum_centroids = embeddings.sum(dim=1)\n",
    "    # we want to subtract out each utterance, prior to calculating the\n",
    "    # the utterance centroid\n",
    "    sum_centroids = sum_centroids.unsqueeze(1)\n",
    "    # we want the mean but not including the utterance itself, so -1\n",
    "    num_utterances = embeddings.shape[1] - 1\n",
    "    centroids = (sum_centroids - embeddings) / num_utterances\n",
    "    return centroids\n",
    "\n",
    "\n",
    "\n",
    "def calc_loss(sim_matrix):\n",
    "    same_idx = list(range(sim_matrix.size(0)))\n",
    "    pos = sim_matrix[same_idx, :, same_idx]\n",
    "    neg = (torch.exp(sim_matrix).sum(dim=2) + 1e-6).log_()\n",
    "    per_embedding_loss = -1 * (pos - neg)\n",
    "    loss = per_embedding_loss.sum()\n",
    "    return loss, per_embedding_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeakerDatasetTIMITPreprocessed(Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, M, shuffle=True, utter_start=0):\n",
    "        \n",
    "        # data path\n",
    "        self.path = data_path\n",
    "        self.utter_num = M\n",
    "        self.file_list = os.listdir(self.path)\n",
    "        self.shuffle=shuffle\n",
    "        self.utter_start = utter_start\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        np_file_list = os.listdir(self.path)\n",
    "        \n",
    "        if self.shuffle:\n",
    "            selected_file = random.sample(np_file_list, 1)[0]  # select random speaker\n",
    "        else:\n",
    "            selected_file = np_file_list[idx]               \n",
    "        \n",
    "        utters = np.load(os.path.join(self.path, selected_file)) # load utterance spectrogram of selected speaker\n",
    "        if self.shuffle:\n",
    "            utter_index = np.random.randint(0, utters.shape[0], self.utter_num)   # select M utterances per speaker\n",
    "            utterance = utters[utter_index]       \n",
    "        else:\n",
    "            utterance = utters[self.utter_start: self.utter_start+self.utter_num] # utterances of a speaker [batch(M), n_mels, frames]\n",
    "\n",
    "        utterance = utterance[:,:,:160]               # TODO implement variable length batch size\n",
    "\n",
    "        utterance = torch.tensor(np.transpose(utterance, axes=(0,2,1)))     # transpose [batch, frames, n_mels]\n",
    "        return utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechEmbedder(nn.Module):\n",
    "    \n",
    "    def __init__(self, mels=40, hidden=128, num_layers=3, proj=64, N=4, M=6):\n",
    "        super(SpeechEmbedder, self).__init__()    \n",
    "        self.LSTM_stack = nn.LSTM(mels, hidden, num_layers=num_layers, batch_first=True)\n",
    "        for name, param in self.LSTM_stack.named_parameters():\n",
    "            if 'bias' in name: # 把bias初始化为0\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight' in name: # weight用xavier初始化\n",
    "                nn.init.xavier_normal_(param) # 这个说不定可以改变用uniform之类的\n",
    "        self.projection = nn.Linear(hidden, proj)\n",
    "        self.n = N\n",
    "        self.m = M\n",
    "        self.proj = proj\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.LSTM_stack(x.float()) #(batch, frames, n_mels) 这个是由于使用了batch_first=True\n",
    "        #only use last frame\n",
    "        x = x[:, -1] # [batch, hidden]\n",
    "        x = self.projection(x) # [batch, projection] \n",
    "        x = F.normalize(x) # x.shape == [batch, projection]\n",
    "        x = torch.reshape(x, (self.n, self.m, self.proj))\n",
    "        return x\n",
    "\n",
    "class GE2ELoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        super(GE2ELoss, self).__init__()\n",
    "        self.w = nn.Parameter(torch.tensor(10.0, device=device))\n",
    "        self.b = nn.Parameter(torch.tensor(-5.0, device=device))\n",
    "\n",
    "        \n",
    "    def forward(self, X, **kwargs):\n",
    "        torch.clamp(self.w, 1e-7) # 论文里面是0, 代码用的1e-7\n",
    "        centroids = get_centroids(X)\n",
    "        cossim = get_cossim(X, centroids)\n",
    "        sim_matrix = self.w*cossim + self.b\n",
    "        loss, _ = calc_loss(sim_matrix)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARMS: {'N': 16, 'lr': 0.001, 'epochs': 100, 'opt': 'Adam', 'debug': False}\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "0:258.0797\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "100:255.9811\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "200:226.0772\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "300:218.8512\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "400:240.0827\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "500:223.8030\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "600:220.4062\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "700:227.0639\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "800:224.8976\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "900:199.5142\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "1000:212.4568\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "1100:220.7292\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "1200:197.7689\n",
      "lr: 0.001\n",
      "lr: 0.001\n",
      "1300:214.1790\n",
      "TIME: 219.354 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# add timing for train\n",
    "def logging(f):\n",
    "    def _f(**kargs):\n",
    "        print(f\"PARMS: {kargs}\")\n",
    "        current = time.time()\n",
    "        result = f(**kargs)\n",
    "        print(f\"TIME: {(time.time() - current):.3f} seconds\")\n",
    "        return result\n",
    "    return _f\n",
    "\n",
    "@logging\n",
    "def train(N=16, lr=0.01, epochs=10, proj=256, hidden=768, num_layers=3, device='cuda', opt='SGD', debug=False, schedule=False):\n",
    "    # define net, loss, optimizer\n",
    "    device = torch.device(device)\n",
    "    N = N\n",
    "    M = 6\n",
    "    embedder_net = SpeechEmbedder(hidden=hidden, num_layers=num_layers, proj=proj, N=N, M=M).to(device)\n",
    "    criterion = GE2ELoss(device)\n",
    "    if opt == 'Adam':\n",
    "        optimizer = torch.optim.Adam([{'params': embedder_net.parameters()},\n",
    "                                 {'params': criterion.parameters()}], lr=lr)\n",
    "    elif opt == 'SGD':\n",
    "        optimizer = torch.optim.SGD([{'params': embedder_net.parameters()},\n",
    "                                    {'params': criterion.parameters()}], lr=lr)\n",
    "    # print(f\"Your optimizer is {optimizer}\")\n",
    "    # schedule\n",
    "    if schedule:\n",
    "        scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "    train_dataset = SpeakerDatasetTIMITPreprocessed('./train_tisv/', M)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=N, drop_last=True, shuffle=True)\n",
    "    # print(len(train_loader))\n",
    "    # train network\n",
    "    epochs = epochs\n",
    "    loss_log = []\n",
    "    iteration = 0\n",
    "    for e in range(epochs):\n",
    "        if schedule:\n",
    "            scheduler.step()\n",
    "        epoch_loss = 0\n",
    "        for batch_id, mel_db in enumerate(train_loader):\n",
    "            # we have only 270 people the batch size is 1.\n",
    "            mel_db = mel_db.to(device)\n",
    "            mel_db = mel_db.flatten(0, 1)\n",
    "            # mel_db = mel_db.reshape(N * M, mel_db.size(2), mel_db.size(3))\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            embeddings = embedder_net(mel_db)\n",
    "            loss = criterion(embeddings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            if iteration % 100 == 0:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(f\"lr: {param_group['lr']}\")\n",
    "                print(f\"{iteration}:{loss.item():.4f}\")\n",
    "            iteration +=1\n",
    "        loss_log.append(epoch_loss)\n",
    "    plt.plot(loss_log)\n",
    "    if not os.path.exists('./models'):\n",
    "        os.makedirs('./models')\n",
    "    save_model_path = f'./models/lr{lr}epochs{epochs}proj{proj}hidden{hidden}num_layers{num_layers}opt{opt}.model'\n",
    "    torch.save(embedder_net.state_dict(), save_model_path)\n",
    "    return save_model_path, loss_log\n",
    "\n",
    "# test loss printout\n",
    "model_path, loss_log = train(N=16, lr=0.001, epochs=100, opt='Adam', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_path, **kargs):\n",
    "    # test network\n",
    "    N = 30\n",
    "    M = 6\n",
    "    test_dataset = SpeakerDatasetTIMITPreprocessed('./test_tisv/', M)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=N, drop_last=True, shuffle=True)\n",
    "    embedder_net = SpeechEmbedder(40, kargs['hidden'], kargs['num_layers'], kargs['proj'], N, M//2)\n",
    "    embedder_net.load_state_dict(torch.load(model_path))\n",
    "    device = torch.device('cuda')\n",
    "    embedder_net.to(device)\n",
    "    embedder_net.eval()\n",
    "    epochs = 10\n",
    "    acc = 0 \n",
    "    avg_EER = 0\n",
    "    for e in range(epochs):\n",
    "        batch_avg_EER = 0\n",
    "        for batch_id, mel_db in enumerate(test_loader):\n",
    "            mel_db = mel_db.to(device)\n",
    "            utt_num = mel_db.shape[1]\n",
    "            assert utt_num % 2 == 0\n",
    "            enrollment, verification = torch.split(mel_db, utt_num // 2, dim=1)\n",
    "            enrollment = embedder_net(enrollment.reshape(-1, mel_db.size(2), mel_db.size(3)))\n",
    "            verification = embedder_net(verification.reshape(-1, mel_db.size(2), mel_db.size(3)))\n",
    "            enrollment_centroids = get_centroids(enrollment)\n",
    "            # what if verification get centorids\n",
    "            sim_matrix = get_cossim(verification, enrollment_centroids) # N * M * proj\n",
    "            \n",
    "            # calculating EER\n",
    "            diff = 1; EER=0; EER_thresh = 0; EER_FAR=0; EER_FRR=0\n",
    "            \n",
    "            for thres in [0.01*i+0.5 for i in range(50)]:\n",
    "                sim_matrix_thresh = sim_matrix>thres\n",
    "                \n",
    "                FAR = (sum([sim_matrix_thresh[i].float().sum()-sim_matrix_thresh[i,:,i].float().sum() for i in range(int(N))])\n",
    "                /(N-1.0)/(float(M/2))/N)\n",
    "    \n",
    "                FRR = (sum([M/2-sim_matrix_thresh[i,:,i].float().sum() for i in range(int(N))])\n",
    "                /(float(M/2))/N)\n",
    "                \n",
    "                # Save threshold when FAR = FRR (=EER)\n",
    "                if diff> abs(FAR-FRR):\n",
    "                    diff = abs(FAR-FRR)\n",
    "                    EER = (FAR+FRR)/2\n",
    "                    EER_thresh = thres\n",
    "                    EER_FAR = FAR\n",
    "                    EER_FRR = FRR\n",
    "            batch_avg_EER += EER\n",
    "            print(\"EER : %0.2f (thres:%0.2f, FAR:%0.2f, FRR:%0.2f)\"%(EER,EER_thresh,EER_FAR,EER_FRR))\n",
    "            # calculating ACC\n",
    "            verification = get_centroids(verification)\n",
    "            result = cosine_distances(verification.detach().cpu().numpy(),enrollment_centroids.detach().cpu().numpy())\n",
    "            batch_acc = sum(list(range(N)) == result.argmin(0)) / N\n",
    "            acc += batch_acc\n",
    "            print(f\"BATCH ACC:{batch_acc}\")\n",
    "        avg_EER += batch_avg_EER/(batch_id+1)\n",
    "    avg_EER = avg_EER / epochs\n",
    "    return acc/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER : 0.22 (thres:0.88, FAR:0.22, FRR:0.22)\n",
      "BATCH ACC:0.3333333333333333\n",
      "EER : 0.28 (thres:0.85, FAR:0.28, FRR:0.28)\n",
      "BATCH ACC:0.36666666666666664\n",
      "EER : 0.29 (thres:0.84, FAR:0.29, FRR:0.28)\n",
      "BATCH ACC:0.2\n",
      "EER : 0.23 (thres:0.86, FAR:0.24, FRR:0.22)\n",
      "BATCH ACC:0.36666666666666664\n",
      "EER : 0.27 (thres:0.87, FAR:0.26, FRR:0.28)\n",
      "BATCH ACC:0.26666666666666666\n",
      "EER : 0.22 (thres:0.87, FAR:0.23, FRR:0.21)\n",
      "BATCH ACC:0.2\n",
      "EER : 0.26 (thres:0.86, FAR:0.25, FRR:0.27)\n",
      "BATCH ACC:0.2\n",
      "EER : 0.27 (thres:0.89, FAR:0.26, FRR:0.28)\n",
      "BATCH ACC:0.2\n",
      "EER : 0.28 (thres:0.84, FAR:0.29, FRR:0.28)\n",
      "BATCH ACC:0.4\n",
      "EER : 0.26 (thres:0.89, FAR:0.27, FRR:0.26)\n",
      "BATCH ACC:0.26666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27999999999999997"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test phrase\n",
    "test(model_path, proj=256, hidden=768, num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-50c0b176a798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# test pipleline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-50c0b176a798>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(**params)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     model_path, total_loss = train(lr=params['lr'], \n\u001b[0m\u001b[1;32m     63\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                        \u001b[0mproj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'proj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "def pipeline(**params):\n",
    "    # training\n",
    "    model_path, total_loss = train(lr=params['lr'], \n",
    "                       epochs=params['max_epochs'], \n",
    "                       proj=params['proj'], \n",
    "                       hidden=params['hidden'], \n",
    "                       num_layers=params['num_layers'],\n",
    "                        opt=params['opt'])\n",
    "    plt.plot(total_loss)\n",
    "    # testing\n",
    "    acc = test(model_path, \n",
    "         proj=params['proj'], \n",
    "         hidden=params['hidden'], \n",
    "         num_layers=params['num_layers'])\n",
    "    return acc\n",
    "\n",
    "# test pipleline\n",
    "pipeline(lr=0.01, max_epochs=30, proj=64, hidden=128, num_layers=3, opt='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-29c5458b193b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     acc = pipeline(lr=params['lr'], max_epochs=params['max_epochs'], proj=params['proj'], \n\u001b[0m\u001b[1;32m     16\u001b[0m                    hidden=params['hidden'], num_layers=params['num_layers'], opt=params['opt'])\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"acc:{acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# parameters sets\n",
    "parameters = {\n",
    "'max_epochs':[100],\n",
    "'lr':[0.01],\n",
    "'proj':[256],\n",
    "'hidden':[768],\n",
    "'num_layers':[3],\n",
    "'opt':['SGD']\n",
    "}\n",
    "grid = ParameterGrid(parameters)\n",
    "max_acc = 0\n",
    "result = pd.DataFrame(grid)\n",
    "\n",
    "for i, params in enumerate(grid):\n",
    "    acc = pipeline(lr=params['lr'], max_epochs=params['max_epochs'], proj=params['proj'], \n",
    "                   hidden=params['hidden'], num_layers=params['num_layers'], opt=params['opt'])\n",
    "    print(f\"acc:{acc}\")\n",
    "    result.loc[i, 'acc'] = acc\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        print(f\"MAX ACC: {max_acc}\")\n",
    "        best_param = params\n",
    "print(max_acc)\n",
    "result.to_csv(f'jupyter_test_{ctime()}log.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
